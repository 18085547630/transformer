{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "from src.dataset import OzeDataset\n",
    "from src.Transformer import Transformer\n",
    "from src.utils import visual_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "DATASET_PATH = 'datasets/dataset.npz'\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "EPOCHS = 20\n",
    "TIME_CHUNK = True\n",
    "\n",
    "# Testing parameters\n",
    "TEST_DATASET_PATH = 'datasets/dataset_test.npz'\n",
    "TEST_MODEL_PATH = 'models/model_00247.pth'\n",
    "\n",
    "# Model parameters\n",
    "K = 672 # Time window length\n",
    "d_model = 48 # Lattent dim\n",
    "q = 8 # Query size\n",
    "v = 8 # Value size\n",
    "h = 4 # Number of heads\n",
    "N = 4 # Number of encoder and decoder to stack\n",
    "pe = None # Positional encoding\n",
    "\n",
    "d_input = 37 # From dataset\n",
    "d_output = 8 # From dataset\n",
    "\n",
    "# Config\n",
    "sns.set()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(OzeDataset(DATASET_PATH),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        num_workers=NUM_WORKERS\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformer with Adam optimizer and MSE loss function\n",
    "net = Transformer(d_input, d_model, d_output, q, v, h, K, N, TIME_CHUNK, pe).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare loss history\n",
    "hist_loss = np.zeros(EPOCHS)\n",
    "for idx_epoch in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    with tqdm(total=len(dataloader.dataset), desc=f\"[Epoch {idx_epoch+1:3d}/{EPOCHS}]\") as pbar:\n",
    "        for idx_batch, (x, y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Propagate input\n",
    "            netout = net(x.to(device))\n",
    "\n",
    "            # Comupte loss\n",
    "            loss = loss_function(netout, y.to(device))\n",
    "\n",
    "            # Backpropage loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': running_loss/(idx_batch+1)})\n",
    "            pbar.update(x.shape[0])\n",
    "        \n",
    "    hist_loss[idx_epoch] = running_loss/len(dataloader)\n",
    "plt.plot(hist_loss, 'o-')\n",
    "print(f\"Loss: {float(hist_loss[-1]):5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatestloader = DataLoader(OzeDataset(TEST_DATASET_PATH),\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            num_workers=NUM_WORKERS\n",
    "                           )\n",
    "net = torch.load(TEST_MODEL_PATH, map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results on a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_sample(datatestloader, net, device)\n",
    "plt.savefig(\"fig.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot encoding attention map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first encoding layer\n",
    "encoder = net.layers_encoding[0]\n",
    "\n",
    "# Get the first attention map\n",
    "attn_map = encoder.attention_map[0].cpu()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(attn_map)\n",
    "plt.savefig(\"attention_map.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.empty(shape=(len(datatestloader.dataset), K, 8))\n",
    "\n",
    "idx_prediction = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(datatestloader, total=len(datatestloader)):\n",
    "        netout = net(x.to(device)).cpu().numpy()\n",
    "        predictions[idx_prediction:idx_prediction+x.shape[0]] = netout\n",
    "        idx_prediction += x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(8, 1)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(40)\n",
    "plt.subplots_adjust(bottom=0.05)\n",
    "\n",
    "delta = np.square(predictions - datatestloader.dataset._y.numpy())\n",
    "\n",
    "for idx_label, (label, ax) in enumerate(zip(datatestloader.dataset.labels['X'], axes)):\n",
    "    \n",
    "    input_data = delta[..., idx_label]\n",
    "    \n",
    "    # For consumption\n",
    "    if label.startswith('Q_'):\n",
    "        y_label_unit = 'kWh'\n",
    "    else:\n",
    "        y_label_unit = 'Â°C'\n",
    "        \n",
    "    mean = input_data.mean(axis=0)\n",
    "    std = input_data.std(axis=0)\n",
    "    \n",
    "    ax.fill_between(np.arange(K), (mean - 3 * std), (mean + 3 * std), alpha=.3)\n",
    "    ax.plot(mean)\n",
    "    \n",
    "    ax.set_title(label)\n",
    "    ax.set_xlabel('time', fontsize=16)\n",
    "    ax.set_ylabel(y_label_unit, fontsize=16)\n",
    "    \n",
    "plt.savefig('error_mean_std.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
